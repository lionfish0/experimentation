{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "\n",
    "#numpy\n",
    "import numpy as np\n",
    "from numpy.random import multivariate_normal #For later example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#advectionGP\n",
    "from advectionGP.models import AdjointAdvectionDiffusionReactionModel as Model #Model module builds basic parts of the PDE problem, combines other classes into full model\n",
    "from advectionGP.sensors import FixedSensorModel #Builds sensor arrays to generate data for foward model or to generate observations for comparison\n",
    "from advectionGP.kernels import EQ #Generates exponentiated quadratic kernel approximation\n",
    "from advectionGP.test import TestKernels #Unit test model\n",
    "from advectionGP.wind import WindFixU #Wind model\n",
    "\n",
    "#Plotting tools\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "\n",
    "# generate sensor locations for training data with shape [total observations, 4], where each row has elements \n",
    "#[lower time location, upper time location, x location, y location]\n",
    "\n",
    "tlocL = np.linspace(6,8,3) # lower time\n",
    "xloc=np.linspace(6,8,5) # x locations\n",
    "yloc=np.linspace(6,8,5) # y locations\n",
    "sensN = len(xloc)*len(yloc) # total number of sensors \n",
    "obsN = len(tlocL) # total time points at which an observation is taken\n",
    "X= np.zeros((obsN*sensN,4)) # obsN*sensN is total observations over all sensors and all times\n",
    "# Build sensor locations\n",
    "X[:,0] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[0] #lower time\n",
    "X[:,2] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[1] # x location\n",
    "X[:,3] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[2] # ylocation\n",
    "X[:,1] = X[:,0]+0.1 # upper time\n",
    "\n",
    "sensors = FixedSensorModel(X,0.1) # establish sensor model arguments are sensor locations and spatial averaging\n",
    "\n",
    "# generate sensor locations for test data with shape [total observations, 4], where each row has elements \n",
    "#[lower time location, upper time location, x location, y location]\n",
    "\n",
    "tlocL = np.linspace(6,9,6) # lower time\n",
    "xloc=np.linspace(6.5,7.5,6) # x locations\n",
    "yloc=np.linspace(6.5,7.5,6) # y locations\n",
    "sensN = len(xloc)*len(yloc) # total number of sensors \n",
    "obsN = len(tlocL) # total time points at which an observation is taken\n",
    "Xtest= np.zeros((obsN*sensN,4)) # obsN*sensN is total observations over all sensors and all times\n",
    "# Build sensor locations\n",
    "Xtest[:,0] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[0] \n",
    "Xtest[:,2] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[1]\n",
    "Xtest[:,3] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[2]\n",
    "Xtest[:,1] = Xtest[:,0]+1\n",
    "\n",
    "sensorsTest = FixedSensorModel(Xtest,1) # establish sensor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/Documents/Research/advectionGP/advectionGP/models.py:68: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  if (dx>=2*self.k_0/np.min(self.u)): print(\"WARNING: spatial grid size does not meet the finite difference advection diffusion stability criteria\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "4.824344232065389\n"
     ]
    }
   ],
   "source": [
    "# Run forward model to generate concentration\n",
    "#u = [0.05,0.] #Advection\n",
    "\n",
    "\n",
    "k_0 = 0.02 #Diffusion\n",
    "R=0.1\n",
    "noiseSD = 0.05 #Observation noise\n",
    "N_feat=300 # number of features used to approximate ground truth GP\n",
    "boundary = ([5,5,5],[10,10,10])# corners of the grid - in units of space\n",
    "k = EQ(0.5, 2.0) # generate EQ kernel arguments are lengthscale and variance\n",
    "res = [100,50,50] # grid size for time, x and y\n",
    "wind=np.cos(np.linspace(0,6*np.pi,res[1]))*0.05\n",
    "u=[]\n",
    "u.append(0*np.ones(res)*wind) #x direction wind\n",
    "u.append(0*np.ones(res)*0.0) # y direction wind\n",
    "windmodel=WindFixU(u) # establish fixed wind model\n",
    "m = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors,windmodel=windmodel,k_0=k_0,R=R) #initiate PDE model to build concentration\n",
    "\n",
    "dt,dx,dy,dx2,dy2,Nt,Nx,Ny = m.getGridStepSize() # useful numbers!\n",
    "\n",
    "z=np.random.normal(0,1.0,N_feat) # Generate z to compute source\n",
    "source=(m.computeSourceFromPhi(z))+5# Compute source\n",
    "#source[source<0]=0\n",
    "\n",
    "#source = np.zeros(m.resolution)\n",
    "##source[0,int(Nx/2)-1,int(Ny/2)-1] = 10.0\n",
    "#source[:,15:25,15:25] = 5\n",
    "#source[:,2:7,2:7] = 25\n",
    "#source[:,7:12,15:20] = 25\n",
    "#source[:,18:28,10:20] = 25\n",
    "\n",
    "concTrain=m.computeConcentration(source) # Compute concentration - runs advection diffusion forward model\n",
    "yTrain= m.computeObservations() # Compute observations with noise uses m.sensormodel for observation locations\n",
    "concTrainNN=m.computeConcentration(source,enforce_nonnegative=True) # Compute concentration - runs advection diffusion forward model\n",
    "yTrainNN= m.computeObservations() # Compute observations with noise uses m.sensormodel for observation locations\n",
    "\n",
    "m.sensormodel=sensorsTest\n",
    "yTest= m.computeObservations()\n",
    "\n",
    "print(np.min(concTrain))\n",
    "print(np.min(yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/Documents/Research/advectionGP/advectionGP/models.py:68: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  if (dx>=2*self.k_0/np.min(self.u)): print(\"WARNING: spatial grid size does not meet the finite difference advection diffusion stability criteria\")\n"
     ]
    }
   ],
   "source": [
    "N_feat = 2000 #Number of features used to infer the source\n",
    "k = EQ(0.5, 2.0) \n",
    "mInfer = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors,windmodel=windmodel,k_0=k_0,R=R) #Initiate new model for inference\n",
    "#%timeit -n1 -r1 regress = mInfer.computeModelRegressors() # Compute regressor matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getHs (all)             83.3ms\n",
      "computeAdjoint (once)   38.8ms\n",
      "getHs & comp.Adjoints 2473.0ms\n",
      "getPhis               15666.0ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Computes the regressor matrix X, using getHs from the sensor model and getPhi from the kernel.\n",
    "X here is used to infer the distribution of z (and hence the source).\n",
    "X is [features x observations]\n",
    "\"\"\"\n",
    "dt,dx,dy,dx2,dy2,Nt,Nx,Ny = mInfer.getGridStepSize()\n",
    "X = np.zeros([mInfer.N_feat,len(mInfer.sensormodel.obsLocs)])\n",
    "\n",
    "adjs = []\n",
    "st = time()\n",
    "for j,H in enumerate(mInfer.sensormodel.getHs(mInfer)):\n",
    "    pass\n",
    "print(\"getHs (all)           %6.1fms\" % (1e3*(time()-st)))\n",
    "\n",
    "st = time()\n",
    "mInfer.computeAdjoint(H)\n",
    "print(\"computeAdjoint (once) %6.1fms\" % (1e3*(time()-st)))\n",
    "\n",
    "\n",
    "st = time()\n",
    "#O(GN)\n",
    "for j,H in enumerate(mInfer.sensormodel.getHs(mInfer)):\n",
    "    adjs.append(mInfer.computeAdjoint(H))\n",
    "print(\"getHs & comp.Adjoints %6.1fms\" % (1e3*(time()-st)))\n",
    "\n",
    "st = time()\n",
    "for i,phi in enumerate(mInfer.kernel.getPhi(mInfer.coords)):\n",
    "    pass\n",
    "print(\"getPhis               %6.1fms\" % (1e3*(time()-st)))\n",
    "\n",
    "st = time()\n",
    "#O(GNF)\n",
    "for i,phi in enumerate(mInfer.kernel.getPhi(mInfer.coords)):\n",
    "    for j,adj in enumerate(adjs):\n",
    "        X[i,j] = np.sum((phi*adj))*dt*dx*dy\n",
    "        \n",
    "print(\"getPhis and products  %6.1fms\" % (1e3*(time()-st)))\n",
    "#phi * v, --> scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhiValues(kernel,particles):\n",
    "    c=1/(kernel.l2)\n",
    "    norm = 1./np.sqrt(kernel.N_feat)\n",
    "    return norm*np.sqrt(2*kernel.sigma2)*np.cos(c*np.einsum('ij,lkj',kernel.W,particles)+kernel.b[:,None,None])\n",
    "\n",
    "st = time()\n",
    "Nsamps = 25\n",
    "scale = Nsamps / dt\n",
    "\n",
    "particles = []\n",
    "N_obs = len(mInfer.sensormodel.obsLocs)\n",
    "for obsi in range(N_obs):\n",
    "    locA = mInfer.sensormodel.obsLocs[obsi,[0,2,3]]\n",
    "    locB = mInfer.sensormodel.obsLocs[obsi,[1,2,3]]\n",
    "    newparticles = np.repeat(locA[None,:],Nsamps,0)\n",
    "    newparticles[:,0]+=np.random.rand(len(newparticles))*(locB[0]-locA[0])\n",
    "    particles.append(newparticles)\n",
    "particles = np.array(particles)\n",
    "\n",
    "newX = np.zeros([N_feat,N_obs])\n",
    "for nit in range(500):#+int(locB[0]/dt)):\n",
    "    particles[:,:,1:]+=np.random.randn(particles.shape[0],particles.shape[1],2)*np.sqrt(2*dt*mInfer.k_0) #plus wind\n",
    "    particles[:,:,0]-=dt\n",
    "    keep = particles[:,0,0]>mInfer.boundary[0][0] #could extend to be within grid space\n",
    "    newX[:,keep] += np.sum(getPhiValues(mInfer.kernel,particles),axis=(1))[:,keep]\n",
    "    if np.sum(keep)==0: \n",
    "        break\n",
    "newX = np.array(newX)/scale\n",
    "print(\"run new particle method  %6.1fms\" % (1e3*(time()-st)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assumed fixed:\n",
    "#griderrorscale = np.sum(next(mInfer.sensormodel.getHs(mInfer)))*(dt*dx*dy)\n",
    "#print(griderrorscale)\n",
    "\n",
    "plt.hist(newX[:,0]/(X[:,0]),np.arange(0,4,0.1)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,15])\n",
    "for plti in range(9):\n",
    "    plt.subplot(3,3,plti+1)\n",
    "    plt.plot(X[:,plti],newX[:,plti],'x')\n",
    "    plt.xlabel('Original X, corrected for error integrating to one')\n",
    "    plt.ylabel('Approximate X, computed using particles')\n",
    "    plt.plot([-0.2,0.2],[-0.2,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(newX.T[:10,5],label='apprx')\n",
    "plt.plot(X.T[:10,5],label='exact')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.title('new approx X')\n",
    "plt.imshow(newX.T[:10,:10],clim=[-.6,.6])\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('old exact X')\n",
    "plt.imshow(X.T[:10,:10],clim=[-.6,.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip for now...\n",
    "#meanZ, covZ = mInfer.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "#sampsZ = np.random.multivariate_normal(meanZ,covZ,15)\n",
    "#sampsSource = []\n",
    "#for s in sampsZ:\n",
    "#    sampsSource.append(mInfer.computeSourceFromPhi(s))\n",
    "#sampsSource = np.array(sampsSource)\n",
    "#uncertainty = np.std(sampsSource,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.contour(uncertainty[5,:,:])#,levels=np.arange(0,0.501,0.125)*np.mean(source))\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "for plti,(title,useX) in enumerate(zip(['original','new','true'],[X,newX,None])):\n",
    "    mInfer.X = useX\n",
    "    plt.subplot(3,2,(plti*2)+1)\n",
    "    plt.title(title)\n",
    "    #regress = m.computeModelRegressors() # Compute regressor matrix\n",
    "    if title!='true':\n",
    "        meanZ, covZ = mInfer.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "        sourceInfer = mInfer.computeSourceFromPhi(meanZ) # Generates estimated source using inferred distributio\n",
    "    else:\n",
    "        sourceInfer = source\n",
    "    plt.imshow(sourceInfer[5,:,:],clim=[0,10])\n",
    "    plt.colorbar()\n",
    "    #plt.contour(uncertainty[5,:,:])\n",
    "    plt.subplot(3,2,(plti*2)+2)\n",
    "    plt.plot(sourceInfer[:,25,25])\n",
    "    \n",
    "    #plt.ylim([0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
